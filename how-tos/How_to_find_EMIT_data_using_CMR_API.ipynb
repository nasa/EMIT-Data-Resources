{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to: Find EMIT Data using NASA's CMR API and Download\n",
    "\n",
    "**Summary**  \n",
    "\n",
    "In this notebook we will open a netCDF4 file from the Earth Surface Minteral Dust Source Investigation (EMIT) as an `xarray.Dataset`. We will then extract extract or clip to an area using a `.geojson` file (will also work with shapefile). The workflows outlined here will work with reflectance L2A or radiance L1B data.\n",
    "\n",
    "**Requirements:**\n",
    "+ A NASA [Earthdata Login](https://urs.earthdata.nasa.gov/) account is required to download EMIT data   \n",
    "+ Selected the `emit_tutorials` environment as the kernel for this notebook.\n",
    "  + For instructions on setting up the environment, follow the the `setup_instructions.md` included in the `/setup/` folder of the repository.  \n",
    "\n",
    "**Learning Objectives**  \n",
    "- How to find EMIT data using NASA's CMR API\n",
    "- How to download programmaticly \n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import geopandas\n",
    "from shapely.geometry import MultiPolygon, Polygon, box"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Obtaining the Concept ID\n",
    "\n",
    "NASA EarthData's unique ID for this dataset (called Concept ID) is needed for searching the dataset. The dataset Digital Object Identifier or DOI can be used to obtain the Concept ID. DOIs can be found by clicking the `Citation` link on the LP DAAC's [EMIT Product Pages](https://lpdaac.usgs.gov/product_search/?query=emit&view=cards&sort=title)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2408750690-LPCLOUD\n"
     ]
    }
   ],
   "source": [
    "doi = '10.5067/EMIT/EMITL2ARFL.001'# EMIT\n",
    "\n",
    "# CMR API base url\n",
    "cmrurl='https://cmr.earthdata.nasa.gov/search/' \n",
    "\n",
    "doisearch = cmrurl + 'collections.json?doi=' + doi\n",
    "concept_id = requests.get(doisearch).json()['feed']['entry'][0]['id']\n",
    "print(concept_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the unique NASA-given concept ID for the EMIT L2A Reflectance dataset, which can be used to retrieve relevant files (or granules)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Searching using CMR API\n",
    "\n",
    "When searching the CMR API, users can provide spatial bounds and date-time ranges to narrow their search. These spatial bounds can be either, points, a bounding box, or a polygon. \n",
    "\n",
    "Specify start time and dates and reformat them to the structure necessary for searching CMR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-03T00:00:00Z,2022-09-03T23:23:59Z\n"
     ]
    }
   ],
   "source": [
    "# Temporal Bound - Year, month, day. Hour, minutes, and seconds (ZULU) can also be included \n",
    "start_date = dt.datetime(2022, 9, 3)\n",
    "end_date = dt.datetime(2022, 9, 3, 23, 23, 59)  \n",
    "\n",
    "# CMR formatted start and end times\n",
    "dt_format = '%Y-%m-%dT%H:%M:%SZ'\n",
    "temporal_str = start_date.strftime(dt_format) + ',' + end_date.strftime(dt_format)\n",
    "print(temporal_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CMR API only allows searching 2000 files at a time. Using `page_num` allows a user to loop through the search result pages. The sections below walk through using Points, Bounding Boxes, and Polygons to spatially constrain a search made using the CMR API. \n",
    "\n",
    "### Search using Points\n",
    "\n",
    "To search using a point we specify a latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20220903T163129_2224611_012/EMIT_L2A_RFL_001_20220903T163129_2224611_012.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20220903T163129_2224611_012/EMIT_L2A_RFLUNCERT_001_20220903T163129_2224611_012.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20220903T163129_2224611_012/EMIT_L2A_MASK_001_20220903T163129_2224611_012.nc'], '82', <MULTIPOLYGON (((-62.086 -39.246, -62.512 -39.943, -61.666 -40.459, -61.241 ...>]]\n"
     ]
    }
   ],
   "source": [
    "# Search using a Point\n",
    "\n",
    "lon = -62.1123\n",
    "lat = -39.89402\n",
    "point_str = str(lon) +','+ str(lat)\n",
    "\n",
    "page_num = 1\n",
    "page_size = 2000 # CMR page size limit\n",
    "\n",
    "granule_arr = []\n",
    "\n",
    "while True:\n",
    "    \n",
    "     # defining parameters\n",
    "    cmr_param = {\n",
    "        \"collection_concept_id\": concept_id, \n",
    "        \"page_size\": page_size,\n",
    "        \"page_num\": page_num,\n",
    "        \"temporal\": temporal_str,\n",
    "        \"point\":point_str\n",
    "    }\n",
    "\n",
    "    granulesearch = cmrurl + 'granules.json'\n",
    "    response = requests.post(granulesearch, data=cmr_param)\n",
    "    granules = response.json()['feed']['entry']\n",
    "       \n",
    "    if granules:\n",
    "        for g in granules:\n",
    "            granule_urls = ''\n",
    "            granule_poly = ''\n",
    "                       \n",
    "            # read cloud cover\n",
    "            cloud_cover = g['cloud_cover']\n",
    "    \n",
    "            # reading bounding geometries\n",
    "            if 'polygons' in g:\n",
    "                polygons= g['polygons']\n",
    "                multipolygons = []\n",
    "                for poly in polygons:\n",
    "                    i=iter(poly[0].split (\" \"))\n",
    "                    ltln = list(map(\" \".join,zip(i,i)))\n",
    "                    multipolygons.append(Polygon([[float(p.split(\" \")[1]), float(p.split(\" \")[0])] for p in ltln]))\n",
    "                granule_poly = MultiPolygon(multipolygons)\n",
    "            \n",
    "            # Get https URLs to .nc files and exclude .dmrpp files\n",
    "            granule_urls = [x['href'] for x in g['links'] if 'https' in x['href'] and '.nc' in x['href'] and '.dmrpp' not in x['href']]\n",
    "            # Add to list\n",
    "            granule_arr.append([granule_urls, cloud_cover, granule_poly])\n",
    "                           \n",
    "        page_num += 1\n",
    "    else: \n",
    "        break\n",
    "print(granule_arr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search using a bounding box\n",
    "For this we'll use a bounding box along the coast of Argentina with a bottom left corner of -62.1123 Longitude, -39.89402 Latitude, and a top right corner of -61.70801 Longitude and -39.57769 Latitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20220903T163129_2224611_012/EMIT_L2A_RFL_001_20220903T163129_2224611_012.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20220903T163129_2224611_012/EMIT_L2A_RFLUNCERT_001_20220903T163129_2224611_012.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20220903T163129_2224611_012/EMIT_L2A_MASK_001_20220903T163129_2224611_012.nc'], '82', <MULTIPOLYGON (((-62.086 -39.246, -62.512 -39.943, -61.666 -40.459, -61.241 ...>]]\n"
     ]
    }
   ],
   "source": [
    "# Search Using a Bounding Box\n",
    "bound = (-62.1123, -39.89402, -61.70801, -39.57769) \n",
    "bound_str = ','.join(map(str,bound))\n",
    "\n",
    "page_num = 1\n",
    "page_size = 2000 # CMR page size limit\n",
    "\n",
    "granule_arr = []\n",
    "\n",
    "while True:\n",
    "    \n",
    "     # defining parameters\n",
    "    cmr_param = {\n",
    "        \"collection_concept_id\": concept_id, \n",
    "        \"page_size\": page_size,\n",
    "        \"page_num\": page_num,\n",
    "        \"temporal\": temporal_str,\n",
    "        \"bounding_box[]\":bound_str\n",
    "    }\n",
    "\n",
    "    granulesearch = cmrurl + 'granules.json'\n",
    "    response = requests.post(granulesearch, data=cmr_param)\n",
    "    granules = response.json()['feed']['entry']\n",
    "       \n",
    "    if granules:\n",
    "        for g in granules:\n",
    "            granule_urls = ''\n",
    "            granule_poly = ''\n",
    "                       \n",
    "            # read cloud cover\n",
    "            cloud_cover = g['cloud_cover']\n",
    "    \n",
    "            # reading bounding geometries\n",
    "            if 'polygons' in g:\n",
    "                polygons= g['polygons']\n",
    "                multipolygons = []\n",
    "                for poly in polygons:\n",
    "                    i=iter(poly[0].split (\" \"))\n",
    "                    ltln = list(map(\" \".join,zip(i,i)))\n",
    "                    multipolygons.append(Polygon([[float(p.split(\" \")[1]), float(p.split(\" \")[0])] for p in ltln]))\n",
    "                granule_poly = MultiPolygon(multipolygons)\n",
    "            \n",
    "            # Get https URLs to .nc files and exclude .dmrpp files\n",
    "            granule_urls = [x['href'] for x in g['links'] if 'https' in x['href'] and '.nc' in x['href'] and '.dmrpp' not in x['href']]\n",
    "            # Add to list\n",
    "            granule_arr.append([granule_urls, cloud_cover, granule_poly])\n",
    "                           \n",
    "        page_num += 1\n",
    "    else: \n",
    "        break\n",
    "print(granule_arr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search a Polygon\n",
    "\n",
    "A polygon can also be used to spatially search using the CMR API. A shapefile, geojson, or other format can be opened as a geopandas dataframe, then reformatted to a geojson format to be sent as a parameter in the CMR search. Note that very complex shapefiles must be simplified, there is a 5000 coordinate limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20220903T163129_2224611_012/EMIT_L2A_RFL_001_20220903T163129_2224611_012.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20220903T163129_2224611_012/EMIT_L2A_RFLUNCERT_001_20220903T163129_2224611_012.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20220903T163129_2224611_012/EMIT_L2A_MASK_001_20220903T163129_2224611_012.nc'], '82', <MULTIPOLYGON (((-62.086 -39.246, -62.512 -39.943, -61.666 -40.459, -61.241 ...>]]\n"
     ]
    }
   ],
   "source": [
    "# Search using a Polygon\n",
    "polygon = geopandas.read_file('../data/isla_gaviota.geojson')\n",
    "geojson = {\"shapefile\": (\"isla_gaviota.geojson\", polygon.geometry.to_json(), \"application/geo+json\")}\n",
    "\n",
    "page_num = 1\n",
    "page_size = 2000 # CMR page size limit\n",
    "\n",
    "granule_arr = []\n",
    "\n",
    "while True:\n",
    "    \n",
    "     # defining parameters\n",
    "    cmr_param = {\n",
    "        \"collection_concept_id\": concept_id, \n",
    "        \"page_size\": page_size,\n",
    "        \"page_num\": page_num,\n",
    "        \"temporal\": temporal_str,\n",
    "        \"simplify-shapefile\": 'true' # this is needed to bypass 5000 coordinates limit of CMR\n",
    "    }\n",
    "\n",
    "    granulesearch = cmrurl + 'granules.json'\n",
    "    response = requests.post(granulesearch, data=cmr_param, files=geojson)\n",
    "    granules = response.json()['feed']['entry']\n",
    "       \n",
    "    if granules:\n",
    "        for g in granules:\n",
    "            granule_urls = ''\n",
    "            granule_poly = ''\n",
    "                       \n",
    "            # read granule title and cloud cover\n",
    "            granule_name = g['title']\n",
    "            cloud_cover = g['cloud_cover']\n",
    "    \n",
    "            # reading bounding geometries\n",
    "            if 'polygons' in g:\n",
    "                polygons= g['polygons']\n",
    "                multipolygons = []\n",
    "                for poly in polygons:\n",
    "                    i=iter(poly[0].split (\" \"))\n",
    "                    ltln = list(map(\" \".join,zip(i,i)))\n",
    "                    multipolygons.append(Polygon([[float(p.split(\" \")[1]), float(p.split(\" \")[0])] for p in ltln]))\n",
    "                granule_poly = MultiPolygon(multipolygons)\n",
    "            \n",
    "            # Get https URLs to .nc files and exclude .dmrpp files\n",
    "            granule_urls = [x['href'] for x in g['links'] if 'https' in x['href'] and '.nc' in x['href'] and '.dmrpp' not in x['href']]\n",
    "            # Add to list\n",
    "            granule_arr.append([granule_urls, cloud_cover, granule_poly])\n",
    "                           \n",
    "        page_num += 1\n",
    "    else: \n",
    "        break\n",
    " \n",
    "print(granule_arr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: At the time this tutorial was made, all 3 searches, point, bounding box, and polygon should result in the same assets being returned.\n",
    "\n",
    "### Creating a Dataframe with the resulting Links\n",
    "\n",
    "A `pandas.dataframe` can be used to store the download URLs and geometries of each file. The EMIT L2A Reflectance and Uncertainty and Mask collection contains 3 assets per granule (reflectance, reflectance uncertainty, and masks). We can see when printing this list, that there are three assets that correspond to a single polygon. For the next step we will place these into a dataframe and 'explode' the dataframe to place each of these in a separate row. If we only want a subset of these assets, we can filter them out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebolch\\AppData\\Local\\Temp\\5\\ipykernel_17572\\2872931741.py:8: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  cmr_results_df.insert(0,'asset_name', cmr_results_df.asset_url.str.split('/',-1).str.get(-1))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_name</th>\n",
       "      <th>asset_url</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>granule_poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMIT_L2A_RFL_001_20220903T163129_2224611_012.nc</td>\n",
       "      <td>https://data.lpdaac.earthdatacloud.nasa.gov/lp...</td>\n",
       "      <td>82</td>\n",
       "      <td>MULTIPOLYGON (((-62.0860977 -39.2463303, -62.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMIT_L2A_RFLUNCERT_001_20220903T163129_2224611...</td>\n",
       "      <td>https://data.lpdaac.earthdatacloud.nasa.gov/lp...</td>\n",
       "      <td>82</td>\n",
       "      <td>MULTIPOLYGON (((-62.0860977 -39.2463303, -62.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMIT_L2A_MASK_001_20220903T163129_2224611_012.nc</td>\n",
       "      <td>https://data.lpdaac.earthdatacloud.nasa.gov/lp...</td>\n",
       "      <td>82</td>\n",
       "      <td>MULTIPOLYGON (((-62.0860977 -39.2463303, -62.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          asset_name  \\\n",
       "0    EMIT_L2A_RFL_001_20220903T163129_2224611_012.nc   \n",
       "0  EMIT_L2A_RFLUNCERT_001_20220903T163129_2224611...   \n",
       "0   EMIT_L2A_MASK_001_20220903T163129_2224611_012.nc   \n",
       "\n",
       "                                           asset_url cloud_cover  \\\n",
       "0  https://data.lpdaac.earthdatacloud.nasa.gov/lp...          82   \n",
       "0  https://data.lpdaac.earthdatacloud.nasa.gov/lp...          82   \n",
       "0  https://data.lpdaac.earthdatacloud.nasa.gov/lp...          82   \n",
       "\n",
       "                                        granule_poly  \n",
       "0  MULTIPOLYGON (((-62.0860977 -39.2463303, -62.5...  \n",
       "0  MULTIPOLYGON (((-62.0860977 -39.2463303, -62.5...  \n",
       "0  MULTIPOLYGON (((-62.0860977 -39.2463303, -62.5...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a pandas dataframe\n",
    "cmr_results_df = pd.DataFrame(granule_arr, columns=[\"asset_url\", \"cloud_cover\", \"granule_poly\"])\n",
    "# Drop granules with empty geometry - if any exist\n",
    "cmr_results_df = cmr_results_df[cmr_results_df['granule_poly'] != '']\n",
    "# Expand so each row contains a single url \n",
    "cmr_results_df = cmr_results_df.explode('asset_url')\n",
    "# Name each asset based on filename\n",
    "cmr_results_df.insert(0,'asset_name', cmr_results_df.asset_url.str.split('/',-1).str.get(-1))\n",
    "\n",
    "cmr_results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we can filter based on the assets that we want or the cloud cover. For this example lets say we are only interested in the Reflectance and the Mask. To filter by asset, we can match strings included in the asset name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_name</th>\n",
       "      <th>asset_url</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>granule_poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMIT_L2A_RFL_001_20220903T163129_2224611_012.nc</td>\n",
       "      <td>https://data.lpdaac.earthdatacloud.nasa.gov/lp...</td>\n",
       "      <td>82</td>\n",
       "      <td>MULTIPOLYGON (((-62.0860977 -39.2463303, -62.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMIT_L2A_MASK_001_20220903T163129_2224611_012.nc</td>\n",
       "      <td>https://data.lpdaac.earthdatacloud.nasa.gov/lp...</td>\n",
       "      <td>82</td>\n",
       "      <td>MULTIPOLYGON (((-62.0860977 -39.2463303, -62.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         asset_name  \\\n",
       "0   EMIT_L2A_RFL_001_20220903T163129_2224611_012.nc   \n",
       "0  EMIT_L2A_MASK_001_20220903T163129_2224611_012.nc   \n",
       "\n",
       "                                           asset_url cloud_cover  \\\n",
       "0  https://data.lpdaac.earthdatacloud.nasa.gov/lp...          82   \n",
       "0  https://data.lpdaac.earthdatacloud.nasa.gov/lp...          82   \n",
       "\n",
       "                                        granule_poly  \n",
       "0  MULTIPOLYGON (((-62.0860977 -39.2463303, -62.5...  \n",
       "0  MULTIPOLYGON (((-62.0860977 -39.2463303, -62.5...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmr_results_df = cmr_results_df[cmr_results_df.asset_name.str.contains('_RFL_') | cmr_results_df.asset_name.str.contains('MASK')]\n",
    "cmr_results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filtering down to the assets you want, you can output a text file with the asset urls or save the entire dataframe, then use a utility such as wget or the DAAC Data Download Tool to download the files. To download you will need to set up NASA Earthdata Login authentication using  a .netrc file. \n",
    "\n",
    "Save the asset urls to a textfile in the `/data/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save text file of asset urls\n",
    "cmr_results_dfs = cmr_results_df[:-1].drop_duplicates(subset=['asset_url']) # Remove any duplicates\n",
    "cmr_results_df.to_csv('../data/emit_asset_urls.txt', columns = ['asset_url'], index=False, header = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "\n",
    "## Downloading Files using the list of URLS/Text File\n",
    "\n",
    "To download the files using the DAAC Data Downloader, clone that repository and execute the python script included from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://git.earthdata.nasa.gov/scm/lpdur/daac_data_download_python.git ../daac_data_download_python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../daac_data_download_python/DAACDataDownload.py -dir ../data/ -f ../data/emit_asset_urls.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download using wget, use the following in the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P ../data/ -i ../data/emit_asset_urls.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Contact Info:  \n",
    "\n",
    "Email: LPDAAC@usgs.gov  \n",
    "Voice: +1-866-573-3222  \n",
    "Organization: Land Processes Distributed Active Archive Center (LP DAAC)¹  \n",
    "Website: <https://lpdaac.usgs.gov/>  \n",
    "Date last modified: 01-12-2023  \n",
    "\n",
    "¹Work performed under USGS contract G15PD00467 for NASA contract NNG14HH33I. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openscapes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:41:22) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3292b2aceff7d39327a7519422d4180a7c9b133202090f26e797e3dd8f2c7877"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
